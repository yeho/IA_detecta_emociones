import streamlit as st
import random
import torch
import speech_recognition as sr
from gtts import gTTS
from io import BytesIO
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from pydub import AudioSegment
import tempfile

# -------- CARGAR MODELO --------
@st.cache_resource
def cargar_modelo_emociones_es():
    modelo = AutoModelForSequenceClassification.from_pretrained(
        "pysentimiento/robertuito-emotion-analysis"
    )
    tokenizer = AutoTokenizer.from_pretrained(
        "pysentimiento/robertuito-emotion-analysis"
    )
    return modelo, tokenizer

modelo_emociones, tokenizer_emociones = cargar_modelo_emociones_es()

def detectar_emocion_espanol(texto):
    inputs = tokenizer_emociones(texto, return_tensors="pt", truncation=True)
    with torch.no_grad():
        logits = modelo_emociones(**inputs).logits
    pred_id = torch.argmax(logits, dim=1).item()
    etiqueta = modelo_emociones.config.id2label[pred_id]
    return etiqueta.lower()
# -------- RESPUESTAS --------
respuestas_emocionales = {
    "joy": ["¬°Qu√© bueno escuchar eso! üòä", "¬°Me alegra mucho! Cu√©ntame m√°s.", "¬°Tu energ√≠a positiva se siente desde aqu√≠!"],
    "sadness": ["Lo siento mucho... ¬øquieres hablar de ello? üòî", "Estoy aqu√≠ para ti. A veces compartir ayuda.", "No est√°s solo. Si te puedo apoyar, dime c√≥mo."],
    "anger": ["Vaya, eso suena molesto. ¬øQu√© pas√≥?", "Tu enojo es v√°lido. ¬øQuieres desahogarte?", "Respirar profundo ayuda, pero tambi√©n expresarlo. Estoy contigo."],
    "disgust": ["Uf, entiendo por qu√© eso te causa rechazo.", "A veces hay cosas que simplemente nos repelen.", "Si quieres sacarlo de tu sistema, aqu√≠ estoy."],
    "fear": ["Parece que eso te inquieta. ¬øQu√© te preocupa?", "No est√°s solo. Estoy aqu√≠ para escucharte.", "El miedo se reduce al compartirlo. Puedes contar conmigo."],
    "surprise": ["¬°Qu√© sorpresa! üòÆ ¬øQu√© pas√≥?", "¬°Eso s√≠ que no lo ve√≠a venir!", "Wow, eso suena inesperado."],
    "neutral": ["Estoy aqu√≠ si quieres platicar de cualquier cosa.","A veces lo normal tambi√©n tiene valor.","¬øC√≥mo te fue hoy?"]
   }

# -------- DETECTAR EMOCI√ìN --------
def detectar_emocion_espanol(texto):
    entrada = "emocion: " + texto
    inputs = tokenizer_emociones.encode(entrada, return_tensors="pt", max_length=512, truncation=True)
    output = modelo_emociones.generate(inputs, max_length=8)
    emocion = tokenizer_emociones.decode(output[0], skip_special_tokens=True)
    return emocion if emocion in respuestas_emocionales else "desconocido"

# -------- RESPUESTA EMOCIONAL --------
def responder_emocionalmente(emocion):
    return random.choice(respuestas_emocionales.get(emocion, respuestas_emocionales["desconocido"]))

# -------- RECONOCIMIENTO DE VOZ --------
def transcribir_audio():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("üéôÔ∏è Escuchando... habla ahora.")
        audio = recognizer.listen(source, timeout=5)
    try:
        texto = recognizer.recognize_google(audio, language="es-MX")
        st.success(f"üó£Ô∏è Dijiste: {texto}")
        return texto
    except sr.UnknownValueError:
        st.error("No pude entender el audio.")
        return None
    except sr.RequestError:
        st.error("Error de conexi√≥n con el servicio de reconocimiento.")
        return None

# -------- TEXTO A VOZ --------
def reproducir_audio(texto):
    tts = gTTS(text=texto, lang='es')
    with tempfile.NamedTemporaryFile(delete=True, suffix=".mp3") as tmp:
        tts.save(tmp.name)
        audio = AudioSegment.from_file(tmp.name, format="mp3")
        audio.export("respuesta.wav", format="wav")
        audio_file = open("respuesta.wav", "rb")
        st.audio(audio_file.read(), format='audio/wav')

# -------- INICIALIZAR SESI√ìN --------
if "historial" not in st.session_state:
    st.session_state.historial = []

# -------- INTERFAZ --------
st.set_page_config(page_title="Agente Emocional con Voz", page_icon="üß†")
st.title("üß† Agente Emocional con Entrada de Voz o Texto")
st.markdown("Este agente detecta tu emoci√≥n en espa√±ol y responde por texto o con voz.")

# Entradas del usuario
modo_entrada = st.radio("Modo de entrada:", ["Texto", "Micr√≥fono"], horizontal=True)
modo_respuesta = st.radio("Modo de respuesta:", ["Texto", "Bocina"], horizontal=True)

# Reiniciar
if st.button("üîÑ Reiniciar sesi√≥n"):
    st.session_state.historial = []
    st.success("Sesi√≥n emocional reiniciada.")

# Obtener entrada
texto_usuario = ""
if modo_entrada == "Texto":
    texto_usuario = st.text_input("Escribe tu mensaje aqu√≠:")
    procesar = st.button("Enviar")
else:
    if st.button("üéôÔ∏è Grabar y procesar voz"):
        texto_usuario = transcribir_audio()
        procesar = True
    else:
        procesar = False

# Procesar entrada
if procesar and texto_usuario:
    emocion = detectar_emocion_espanol(texto_usuario)
    respuesta = responder_emocionalmente(emocion)

    st.session_state.historial.append({
        "usuario": texto_usuario,
        "emocion": emocion,
        "respuesta": respuesta
    })

    if modo_respuesta == "Texto":
        st.markdown(f"**Agente ({emocion}):** {respuesta}")
    else:
        reproducir_audio(respuesta)

# Mostrar historial
if st.session_state.historial:
    st.markdown("### üóÇÔ∏è Historial de esta sesi√≥n:")
    for entrada in reversed(st.session_state.historial):
        st.markdown(f"**T√∫:** {entrada['usuario']}")
        st.markdown(f"*Emoci√≥n detectada:* `{entrada['emocion']}`")
        st.markdown(f"**Agente:** {entrada['respuesta']}")
        st.markdown("---")
